{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Follow full tutorials here: https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/001%20-%20Introduction.ipynb\n",
    "\n",
    "## Pre-requisites\n",
    "This part assumes that the terraform backend has been provisioned properly (and has not been destroyed).\n",
    "To follow this guide, a Redshift cluster has to be provisioned.\n",
    "Simply run `terraform apply` in the current folder, you will get a cluster up and running to get this notebook runing and practice AWS wrangler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "wr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sessions\n",
    "Create customized session using boto3.Session()\n",
    "Reference: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env.aws_credentials')\n",
    "AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY')\n",
    "AWS_SECRET_KEY = os.getenv('AWS_SECRET_KEY')\n",
    "AWS_REGION = os.getenv('AWS_REGION')\n",
    "# using a custom boto3 session using my own aws development credentials\n",
    "my_session = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    "    region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.does_object_exist(\"s3://noaa-ghcn-pds/fake\", boto3_session=my_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amazon S3\n",
    "bucket_name = \"zoomcamp-extracted-data\"\n",
    "# check whether the parquet file from the prefect exercise exists in the s3 bucket\n",
    "wr.s3.does_object_exist(f\"s3://{bucket_name}/yellow_tripdata_2023-09.parquet\", boto3_session=my_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading object to a file path\n",
    "\n",
    "local_file_dir = \"./download/\"\n",
    "s3_file_name = \"yellow_tripdata_2023-09.parquet\"\n",
    "s3_file_path = f\"s3://{bucket_name}/{s3_file_name}\"\n",
    "local_file = os.path.join(local_file_dir, s3_file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.download(path=s3_file_path, local_file=local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-01 00:15:37</td>\n",
       "      <td>2023-09-01 00:20:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-09-01 00:18:40</td>\n",
       "      <td>2023-09-01 00:30:28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-09-01 00:35:01</td>\n",
       "      <td>2023-09-01 00:39:04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-09-01 00:45:45</td>\n",
       "      <td>2023-09-01 00:47:37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>141</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-09-01 00:01:23</td>\n",
       "      <td>2023-09-01 00:38:05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.77</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2023-09-01 00:15:37   2023-09-01 00:20:21              1.0   \n",
       "1         2  2023-09-01 00:18:40   2023-09-01 00:30:28              2.0   \n",
       "2         2  2023-09-01 00:35:01   2023-09-01 00:39:04              1.0   \n",
       "3         2  2023-09-01 00:45:45   2023-09-01 00:47:37              1.0   \n",
       "4         2  2023-09-01 00:01:23   2023-09-01 00:38:05              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.80         1.0                  N           163           230   \n",
       "1           2.34         1.0                  N           236           233   \n",
       "2           1.62         1.0                  N           162           236   \n",
       "3           0.74         1.0                  N           141           229   \n",
       "4           9.85         1.0                  N           138           230   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          6.5    3.5      0.5        0.00           0.0   \n",
       "1             1         14.2    1.0      0.5        2.00           0.0   \n",
       "2             1          8.6    1.0      0.5        2.00           0.0   \n",
       "3             1          5.1    1.0      0.5        1.00           0.0   \n",
       "4             1         45.0    6.0      0.5       17.02           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         11.50                   2.5         0.00  \n",
       "1                    1.0         21.20                   2.5         0.00  \n",
       "2                    1.0         15.60                   2.5         0.00  \n",
       "3                    1.0         11.10                   2.5         0.00  \n",
       "4                    1.0         73.77                   2.5         1.75  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df = pd.read_parquet(local_file)\n",
    "taxi_df = taxi_df.head(100)\n",
    "\n",
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trips_data_all masteruser\n"
     ]
    }
   ],
   "source": [
    "\n",
    "REDSHIFT_DATABASE = os.getenv('REDSHIFT_DATABASE')\n",
    "REDSHIFT_USER = os.getenv('REDSHIFT_USER')\n",
    "REDSHIFT_PASSWORD = os.getenv('REDSHIFT_PASSWORD')\n",
    "print(REDSHIFT_DATABASE, REDSHIFT_USER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1],)\n"
     ]
    }
   ],
   "source": [
    "# need to ensure that redshift vpc cluster has security group to be properly set up to allow inbound access via port 5439\n",
    "glue_connection_name = \"zoomcamp_redshift_glue_connection\"\n",
    "con = wr.redshift.connect(\n",
    "    connection=glue_connection_name,\n",
    "    dbname=REDSHIFT_DATABASE,\n",
    "    boto3_session=my_session\n",
    "    )\n",
    "\n",
    "# testing connection\n",
    "with con.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT 1;\")\n",
    "    print(cursor.fetchall())\n",
    "\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([100],)\n"
     ]
    }
   ],
   "source": [
    "s3_staging_folder = \"copy_to_redshift_staging\"\n",
    "table_name = \"demo_taxi_data\"\n",
    "# copy the dataframe to redshift cluster\n",
    "wr.redshift.copy(\n",
    "    df=taxi_df,\n",
    "    path=f\"s3://{bucket_name}/{s3_staging_folder}\",\n",
    "    con=con,\n",
    "    table=table_name,\n",
    "    schema=\"public\",\n",
    "    boto3_session=my_session\n",
    ")\n",
    "\n",
    "# wr.redshift.to_sql(\n",
    "#     df=taxi_df,\n",
    "#     table=table_name,\n",
    "#     schema=\"public\",\n",
    "#     con=con,\n",
    "#     mode='overwrite'\n",
    "# )\n",
    "\n",
    "with con.cursor() as cursor:\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Session\n",
    "Please ensure you destroy provisioned resources to avoid any charges.\n",
    "Simply run `terraform destroy` in the `aws_wrangler_tutorial` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift Serverless\n",
    "\n",
    "This section executes the COPY command from S3 bucket to Redshift Serverless\n",
    "\n",
    "## Provision Redshift Serverless\n",
    "Go into week1's `Terraform/` folder and run:\n",
    "If using aws-wranger.redshift.connect to connect to serverless:\n",
    "```bash\n",
    "terraform apply -target=aws_redshiftserverless_namespace.zoomcamp_dataset -target=aws_redshiftserverless_workgroup.zoomcamp_dataset -target=aws_glue_connection.redshift_serverless_glue\n",
    "```\n",
    "\n",
    "if connecting using redshift-connector (which is demonstrated in this notebook):\n",
    "```bash\n",
    "terraform apply -target=aws_redshiftserverless_namespace.zoomcamp_dataset -target=aws_redshiftserverless_workgroup.zoomcamp_dataset\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1],)\n"
     ]
    }
   ],
   "source": [
    "# creating new connection to the Redshift Serverless via Glue Connection (provisioned via Terraform)\n",
    "# code ref: https://github.com/aws/amazon-redshift-python-driver/blob/master/tutorials/001%20-%20Connecting%20to%20Amazon%20Redshift.ipynb\n",
    "\n",
    "import redshift_connector\n",
    "con = redshift_connector.connect(\n",
    "    iam=True,\n",
    "    host=\"zoomcamp-redshift-workgroup.571772404385.us-east-2.redshift-serverless.amazonaws.com\",\n",
    "    port=5439,\n",
    "    database=REDSHIFT_DATABASE,\n",
    "    # user=REDSHIFT_USER,\n",
    "    # password=REDSHIFT_PASSWORD,\n",
    "    is_serverless=True,\n",
    "    serverless_work_group='zoomcamp-redshift-workgroup',\n",
    ")\n",
    "# test out the connection\n",
    "\n",
    "with con.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT 1;\")\n",
    "    print(cursor.fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'trips_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with con.cursor() as cursor:\n",
    "    cursor.execute(f\"DROP TABLE {table_name};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS trips_data (\n",
    "\"VendorID\" BIGINT, \n",
    "tpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
    "tpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
    "passenger_count FLOAT(53), \n",
    "trip_distance FLOAT(53), \n",
    "\"RatecodeID\" FLOAT(53), \n",
    "store_and_fwd_flag TEXT, \n",
    "\"PULocationID\" BIGINT, \n",
    "\"DOLocationID\" BIGINT, \n",
    "payment_type BIGINT, \n",
    "fare_amount FLOAT(53), \n",
    "extra FLOAT(53), \n",
    "mta_tax FLOAT(53), \n",
    "tip_amount FLOAT(53), \n",
    "tolls_amount FLOAT(53), \n",
    "improvement_surcharge FLOAT(53), \n",
    "total_amount FLOAT(53), \n",
    "congestion_surcharge FLOAT(53), \n",
    "airport_fee FLOAT(53)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table trips_data has been created in redshift.\n",
      "Table trips_data currently contains [0] records.\n"
     ]
    }
   ],
   "source": [
    "with con.cursor() as cursor:\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Table {table_name} has been created in redshift.\")\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "    result = cursor.fetchone()\n",
    "    print(f\"Table {table_name} currently contains {result} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COPY trips_data\n",
      "FROM 's3://zoomcamp-extracted-data/yellow_tripdata_2023-09.parquet'\n",
      "FORMAT PARQUET\n",
      "IAM_ROLE 'arn:aws:iam::571772404385:role/redshift-service-role'\n",
      "REGION 'us-east-2';\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AWS_ROLE_ARN_REDSHIFT = os.getenv('AWS_ROLE_ARN_REDSHIFT')\n",
    "\n",
    "# COPY parquet file from S3 and Load to Redshift\n",
    "sql_copy_command = f\"\"\"\n",
    "COPY {table_name}\n",
    "FROM '{s3_file_path}'\n",
    "FORMAT PARQUET\n",
    "IAM_ROLE '{AWS_ROLE_ARN_REDSHIFT}'\n",
    "REGION '{AWS_REGION}';\n",
    "\"\"\"\n",
    "print(sql_copy_command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from S3 has been copied over to Redshift database: trips_data_all\n",
      "Number of rows in 'trips_data' table: [100000]\n"
     ]
    }
   ],
   "source": [
    "with con.cursor() as cursor:\n",
    "    cursor.execute(sql_copy_command)\n",
    "    print(f\"Data from S3 has been copied over to Redshift database: {REDSHIFT_DATABASE}\")\n",
    "    con.commit()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM trips_data;\")\n",
    "    result = cursor.fetchone()\n",
    "    print(f\"Number of rows in 'trips_data' table: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([100000],)\n"
     ]
    }
   ],
   "source": [
    "## Checking records have been copied over to redshift serverless\n",
    "con = redshift_connector.connect(\n",
    "    iam=True,\n",
    "    host=\"zoomcamp-redshift-workgroup.571772404385.us-east-2.redshift-serverless.amazonaws.com\",\n",
    "    port=5439,\n",
    "    database=REDSHIFT_DATABASE,\n",
    "    # user=REDSHIFT_USER,\n",
    "    # password=REDSHIFT_PASSWORD,\n",
    "    is_serverless=True,\n",
    "    serverless_work_group='zoomcamp-redshift-workgroup',\n",
    ")\n",
    "\n",
    "with con.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM trips_data;\")\n",
    "    print(cursor.fetchall())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
